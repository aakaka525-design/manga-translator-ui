#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯• Vue/API è·¯å¾„ç¿»è¯‘ï¼ˆæ¨¡æ‹Ÿ _translate_single_image çš„å®Œæ•´æµç¨‹ï¼‰
ç›´æ¥è°ƒç”¨æ ¸å¿ƒé€»è¾‘ï¼Œæ— éœ€å¯åŠ¨ HTTP æœåŠ¡å™¨å’Œè®¤è¯ã€‚
"""
import asyncio
import sys
import os
import time

# åœ¨ PyTorch åˆå§‹åŒ–å‰è®¾ç½®æ˜¾å­˜ä¼˜åŒ–
os.environ.setdefault('PYTORCH_ALLOC_CONF', 'expandable_segments:True')

async def run_translate_single_image_demo():
    from pathlib import Path

    repo_root = Path(__file__).resolve().parents[2]
    default_image = repo_root / (
        "manga_translator/server/data/raw/"
        "isekai-dragondick-knight-commander/chapter-1/001.jpg"
    )
    default_output = repo_root / "result/test_vue_api_output.jpg"
    image_path = Path(os.getenv("MANGA_TEST_IMAGE", str(default_image)))
    output_path = Path(os.getenv("MANGA_TEST_OUTPUT", str(default_output)))
    
    if not image_path.exists():
        print(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
        return
    
    print(f"ğŸ“– è¾“å…¥å›¾ç‰‡: {image_path}")
    print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}")
    print(f"ğŸ“ å›¾ç‰‡å¤§å°: {image_path.stat().st_size / 1024:.1f} KB")
    print()
    
    # æ¨¡æ‹Ÿ Vue/API è·¯å¾„: _translate_single_image
    payload = image_path.read_bytes()
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    t_start = time.time()
    
    try:
        from manga_translator.server.core.config_manager import load_default_config
        from manga_translator.server.core.task_manager import get_global_translator, get_server_config
        from manga_translator.server.main import _ensure_runtime_server_config
        from manga_translator.server.request_extraction import get_ctx
        from starlette.requests import Request
        
        resolved_use_gpu = _ensure_runtime_server_config()
        runtime_cfg = get_server_config()

        # 1. åŠ è½½é»˜è®¤é…ç½®
        config = load_default_config()
        print(f"âœ… é…ç½®åŠ è½½å®Œæˆ")
        print(f"   ç¿»è¯‘å™¨: {config.translator.translator}")
        print(f"   ç›®æ ‡è¯­è¨€: {config.translator.target_lang}")
        print(f"   attempts: {config.translator.attempts}")
        print(
            f"   runtime: use_gpu={resolved_use_gpu}, "
            f"source={runtime_cfg.get('_runtime_config_source')}"
        )
        print()
        
        # 2. æ„é€  fake requestï¼ˆå’Œ v1_translate.py ä¸€è‡´ï¼‰
        fake_request = Request({
            "type": "http", 
            "method": "POST", 
            "path": "/api/v1/translate/page", 
            "headers": []
        })
        
        # 3. è°ƒç”¨ get_ctxï¼ˆè¿™æ˜¯ Vue/API è·¯å¾„çš„æ ¸å¿ƒï¼‰
        print(f"ğŸ”„ å¼€å§‹ç¿»è¯‘ï¼ˆVue/API è·¯å¾„: get_ctx â†’ _run_translate_syncï¼‰...")
        t_translate_start = time.time()
        
        ctx = await get_ctx(fake_request, config, payload, "normal")
        
        t_translate_end = time.time()
        translate_ms = (t_translate_end - t_translate_start) * 1000
        
        # 4. æ£€æŸ¥ç»“æœ
        if not getattr(ctx, "result", None):
            print(f"âŒ ç¿»è¯‘æ²¡æœ‰äº§ç”Ÿè¾“å‡ºå›¾ç‰‡ (ctx.result is None)")
            print(f"   ctx attributes: {[a for a in dir(ctx) if not a.startswith('_')]}")
            return
        
        # 5. ä¿å­˜ç»“æœï¼ˆå¤„ç† RGBAâ†’RGB è½¬æ¢ï¼‰
        from PIL import Image
        result_image = ctx.result
        if output_path.suffix.lower() in {".jpg", ".jpeg"} and result_image.mode in {"RGBA", "LA"}:
            background = Image.new("RGB", result_image.size, (255, 255, 255))
            if "A" in result_image.getbands():
                background.paste(result_image.convert("RGB"), mask=result_image.getchannel("A"))
            else:
                background.paste(result_image.convert("RGB"))
            result_image = background
        elif result_image.mode not in {"RGB", "L"}:
            result_image = result_image.convert("RGB")
        result_image.save(output_path)
        
        regions_count = len(getattr(ctx, "text_regions", []) or [])
        translator = get_global_translator()
        
        t_total = time.time() - t_start
        
        print()
        print("=" * 60)
        print("ğŸ“Š ç¿»è¯‘ç»“æœ")
        print("=" * 60)
        print(f"   âœ… ç¿»è¯‘æˆåŠŸï¼")
        print(f"   ğŸ“ æ£€æµ‹åˆ°æ–‡æœ¬åŒºåŸŸæ•°: {regions_count}")
        print(f"   â±ï¸  ç¿»è¯‘è€—æ—¶: {translate_ms:.0f}ms ({translate_ms/1000:.1f}s)")
        print(f"   â±ï¸  æ€»è€—æ—¶: {t_total*1000:.0f}ms ({t_total:.1f}s)")
        print(f"   ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"   ğŸ’¾ è¾“å‡ºå¤§å°: {output_path.stat().st_size / 1024:.1f} KB")
        print(f"   âš™ï¸  translator.device: {getattr(translator, 'device', 'unknown')}")
        
        # æ‰“å°ç¿»è¯‘çš„æ–‡æœ¬
        if hasattr(ctx, 'text_regions') and ctx.text_regions:
            print()
            print("ğŸ“– ç¿»è¯‘çš„æ–‡æœ¬:")
            for i, region in enumerate(ctx.text_regions):
                src = getattr(region, 'text', '') or ''
                tgt = getattr(region, 'translation', '') or ''
                if src or tgt:
                    print(f"   [{i+1}] {src[:50]} â†’ {tgt[:50]}")
        
    except Exception as exc:
        t_total = time.time() - t_start
        print(f"âŒ ç¿»è¯‘å¤±è´¥ï¼")
        print(f"   å¼‚å¸¸ç±»å‹: {exc.__class__.__name__}")
        print(f"   å¼‚å¸¸ä¿¡æ¯: {exc}")
        print(f"   â±ï¸  è€—æ—¶: {t_total*1000:.0f}ms ({t_total:.1f}s)")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”¬ Vue/API è·¯å¾„ç¿»è¯‘æµ‹è¯•")
    print("=" * 60)
    print()
    asyncio.run(run_translate_single_image_demo())
